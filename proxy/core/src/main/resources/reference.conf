cloudstate.proxy {
    dev-mode-enabled = false
    ready-timeout = 1s
    http-interface = "0.0.0.0"
    http-port = 9000
    http-port = ${?HTTP_PORT}
    user-function-interface = "127.0.0.1"
    user-function-port = 8080
    user-function-port = ${?USER_FUNCTION_PORT}
    metrics-port = 9090
    metrics-port = ${?METRICS_PORT}
    relay-timeout = 1m
    relay-buffer-size = 100
    graceful-termination-timeout = 10s
    passivation-timeout = 30s // Keep short for testing purposes
    number-of-shards = 100
    proxy-parallelism = 100
    backoff {
      min = 1s
      max = 10s
      random-factor = 0.2
    }
    // The maximum number of outstanding commands that are allowed to be in progress.
    // If zero, this means unlimited.
    container-concurrency = 1
    container-concurrency = ${?CONTAINER_CONCURRENCY}
    // The maximum amount of time that commands are allowed to execute for before timing out.
    action-timeout = 10s
    action-timeout-poll-period = 5s

    stats {
        report-period = 1s
    }

    autoscaler {
        target-concurrency {
            user-function = 1
            user-function = ${?USER_FUNCTION_TARGET_CONCURRENCY}

            request = 50
            request = ${?REQUEST_TARGET_CONCURRENCY}

            window = 1m
            window = ${?TARGET_CONCURRENCY_WINDOW}
        }

        scale-up-stable-deadline = 3m
        scale-up-stable-deadline = ${?SCALE_UP_STABLE_DEADLINE}
        scale-down-stable-deadline = 30s
        scale-down-stable-deadline = ${?SCALE_DOWN_STABLE_DEADLINE}

        request-rate {
            threshold-factor = 1.5
            threshold-factor = ${?REQUEST_RATE_THRESHOLD_FACTOR}

            window = 6s
            threshold-factor = ${?REQUEST_RATE_WINDOW}
        }

        max-scale-factor = 0.0
        max-scale = 2
        max-members = 100

        tick-period = 2s
    }
}
